{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whatsapp Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION\n",
    "# Names list - CHANGE THESE to include any personal names to remove.\n",
    "names = { \n",
    "            'old_name' : 'new_name',\n",
    "            'Joe' : 'J',\n",
    "            'Dom' : 'D', \n",
    "}\n",
    "\n",
    "# Censor list - CHANGE THESE to include any words you want to hide, I'd suggest including the above names.\n",
    "censor_list = [\n",
    "    ['word_to_be_censored','censored_word'],\n",
    "    ['best','good'],\n",
    "    ['amazing','alright'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>name</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-02-21 09:09:00</td>\n",
       "      <td>Joe</td>\n",
       "      <td>Wow what an amazing chat!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-21 09:10:00</td>\n",
       "      <td>Dom</td>\n",
       "      <td>I agree, it is amazing!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-02-21 09:12:00</td>\n",
       "      <td>Joe</td>\n",
       "      <td>You're the best!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-02-21 09:12:00</td>\n",
       "      <td>Dom</td>\n",
       "      <td>No, you are the best!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-21 09:12:00</td>\n",
       "      <td>Dom</td>\n",
       "      <td>&lt;Media omitted&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  name                    message\n",
       "0 2019-02-21 09:09:00   Joe  Wow what an amazing chat!\n",
       "1 2019-02-21 09:10:00   Dom    I agree, it is amazing!\n",
       "2 2019-02-21 09:12:00   Joe           You're the best!\n",
       "3 2019-02-21 09:12:00   Dom      No, you are the best!\n",
       "4 2019-02-21 09:12:00   Dom            <Media omitted>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in CSV\n",
    "df = pd.read_csv('parsed_export.csv',sep=\"|\")\n",
    "# convert to datetime\n",
    "df['datetime']=pd.to_datetime(df['datetime'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Censoring\n",
    "In the interest of privacy I would suggest removing any personal details. The below code allows you to censor names, locations, ideas and whatever else you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>name</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-02-21 09:09:00</td>\n",
       "      <td>J</td>\n",
       "      <td>Wow what an alright chat!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-21 09:10:00</td>\n",
       "      <td>D</td>\n",
       "      <td>I agree, it is alright!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-02-21 09:12:00</td>\n",
       "      <td>J</td>\n",
       "      <td>You're the good!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-02-21 09:12:00</td>\n",
       "      <td>D</td>\n",
       "      <td>No, you are the good!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-21 09:12:00</td>\n",
       "      <td>D</td>\n",
       "      <td>&lt;Media omitted&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime name                    message\n",
       "0 2019-02-21 09:09:00    J  Wow what an alright chat!\n",
       "1 2019-02-21 09:10:00    D    I agree, it is alright!\n",
       "2 2019-02-21 09:12:00    J           You're the good!\n",
       "3 2019-02-21 09:12:00    D      No, you are the good!\n",
       "4 2019-02-21 09:12:00    D            <Media omitted>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Censor name and words\n",
    "\n",
    "# Replace messages\n",
    "def censor(message):\n",
    "    for censor in censor_list:\n",
    "        message = message.replace(censor[0],censor[1])\n",
    "    \n",
    "    return message\n",
    "\n",
    "# remove any spaces\n",
    "df['name'] = df['name'].str.strip()\n",
    "# Replace names\n",
    "df = df.replace(\n",
    "    {\n",
    "        'name' : names\n",
    "    }\n",
    ")\n",
    "\n",
    "# censor all messages\n",
    "df['message'] = df['message'].apply(censor)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gotchas\n",
    "Every Media message has been replaced with \"<Media Omitted>\", we need to remove these or they might be our most popular words.\n",
    "\n",
    "Capitalized words will show up twice too, so \"Joe\" and \"joe\" might both show up in our word cloud. To avoid this we can capitalize, or lowercase everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>name</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-02-21 09:09:00</td>\n",
       "      <td>J</td>\n",
       "      <td>Wow What An Alright Chat!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-21 09:10:00</td>\n",
       "      <td>D</td>\n",
       "      <td>I Agree, It Is Alright!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-02-21 09:12:00</td>\n",
       "      <td>J</td>\n",
       "      <td>You'Re The Good!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-02-21 09:12:00</td>\n",
       "      <td>D</td>\n",
       "      <td>No, You Are The Good!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime name                    message\n",
       "0 2019-02-21 09:09:00    J  Wow What An Alright Chat!\n",
       "1 2019-02-21 09:10:00    D    I Agree, It Is Alright!\n",
       "2 2019-02-21 09:12:00    J           You'Re The Good!\n",
       "3 2019-02-21 09:12:00    D      No, You Are The Good!"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with media messages\n",
    "df = df[df['message'] != '<Media omitted>']\n",
    "\n",
    "# Capitalize everything\n",
    "df['message'] = df['message'].apply(lambda x: x.title())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop words\n",
    "If we now look at our most common words we have what are known as \"stop words\" in NLP. These are commonly used words that are considered unimportant to the content of a message. Think words like \"and, to,I\". These are considered important in a lot of Natural Language Processing now, but they make for rubbish word clouds. NLTK can help us here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/joern/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/joern/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You Get Like Back Please Joe'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_stopwords(message):\n",
    "  text_tokens = word_tokenize(message)\n",
    "  # remove stopwrods and punctuation\n",
    "  # all words need to be uppercased\n",
    "  return ' '.join([word.capitalize() for word in text_tokens if not word in stopwords.words() if word.isalnum()])\n",
    "\n",
    "remove_stopwords(\"You're can get now just like , one take back please joe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>name</th>\n",
       "      <th>message</th>\n",
       "      <th>message_without_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-02-21 09:09:00</td>\n",
       "      <td>J</td>\n",
       "      <td>Wow What An Alright Chat!</td>\n",
       "      <td>Wow What An Alright Chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-21 09:10:00</td>\n",
       "      <td>D</td>\n",
       "      <td>I Agree, It Is Alright!</td>\n",
       "      <td>I Agree It Is Alright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-02-21 09:12:00</td>\n",
       "      <td>J</td>\n",
       "      <td>You'Re The Good!</td>\n",
       "      <td>The Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-02-21 09:12:00</td>\n",
       "      <td>D</td>\n",
       "      <td>No, You Are The Good!</td>\n",
       "      <td>No You Are The Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime name                    message  \\\n",
       "0 2019-02-21 09:09:00    J  Wow What An Alright Chat!   \n",
       "1 2019-02-21 09:10:00    D    I Agree, It Is Alright!   \n",
       "2 2019-02-21 09:12:00    J           You'Re The Good!   \n",
       "3 2019-02-21 09:12:00    D      No, You Are The Good!   \n",
       "\n",
       "  message_without_stopwords  \n",
       "0  Wow What An Alright Chat  \n",
       "1     I Agree It Is Alright  \n",
       "2                  The Good  \n",
       "3       No You Are The Good  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the stopwords from our dataframe\n",
    "df['message_without_stopwords'] = df['message'].apply(remove_stopwords)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out this great word cloud site. This actually does a lot of the work for you in removing stop words, and doing the frequency count. In order to use this we need to get an output file of just our text messages. \n",
    "df['message_without_stopwords'].to_csv('output/Formatted_messages.csv',index=False)\n",
    "# Maybe we also want to make individual word clouds per \"friend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or generate a file per user\n",
    "for name in names.values():\n",
    "    df[df.name == name]['message_without_stopwords'].to_csv('output/' + name +'_messages.csv', index=False,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordCloud time\n",
    "This is everything you need for my better version of a wordcloud."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
